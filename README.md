# LibriSpeechTextSummarization

A fullâ€‘stack project that ingests raw audio, cleans it, transcribes speech to text, performs NLP (Namedâ€‘Entity Recognition and multiâ€‘level summarisation) and serves the results via a minimal Flask web UI.

---

## âœ¨ Key Features

| Stage                        | Tech                                               | Purpose                                                      |
| ---------------------------- | -------------------------------------------------- | ------------------------------------------------------------ |
| **Audio cleaning**           | `librosa`, `soundfile`                             | Resample to 16â€¯kHz, trim silence, normalise loudness         |
| **Speech recognition**       | **OpenAIÂ Whisper** (`openaiâ€‘whisper`, `torch`)     | Accurate multilingual ASR                                    |
| **Text cleaning**            | pureÂ Python                                        | Remove fillers, normalise casing & punctuation               |
| **Namedâ€‘Entity Recognition** | **spaCyÂ â„¹ï¸** (EnglishÂ `en_core_web_sm` by default) | ExtractÂ `PERSON`,Â `ORG`,Â `LOC`, etc.                         |
| **Summarisation**            | **T5â€‘base** viaÂ `transformers`                     | Generate long, short & tiny summaries                        |
| **Web UI**                   | **Flask** + vanillaÂ HTML/CSS                       | Upload audio â†’ view cleaned transcript, entities & summaries |
| **Batch CLI tools**          | Python scripts                                     | Automate each stage for large corpora                        |
| **Configâ€‘driven**            | `configs.yaml`                                     | Centralise all parameters                                    |

---

## ğŸ—‚ï¸ Directory Layout

```text
project_root/
â”œâ”€ config/
â”‚  â””â”€ configs.yaml              # all tunable parameters
â”œâ”€ data/
â”‚  â”œâ”€ raw_audio/                # your unprocessed clips
â”‚  â”œâ”€ clean_audio/              # output from audio_cleaning.py
â”‚  â”œâ”€ transcripts/              # Whisper + cleaned CSV/parquet
â”‚  â””â”€ nlp/                      # NER & summaries (optional)
â”œâ”€ src/
â”‚  â”œâ”€ audio_cleaning.py         # stageÂ 1
â”‚  â”œâ”€ whisper_transcribe.py     # stageÂ 2 (batch)
â”‚  â”œâ”€ text_cleaning.py          # stageÂ 3
â”‚  â”œâ”€ ner_summarise.py          # stageÂ 4 (spaCyÂ +Â T5) â˜… NEW
â”‚  â””â”€ app.py                    # Flask UI
â””â”€ README.md
```

---

## ğŸ”§ Setup

1. **Clone & create venv**

   ```bash
   git clone â€¦
   cd project_root
   python -m venv venv && source venv/bin/activate  # Windows: venv\Scripts\activate
   ```
2. **Install core deps**

   ```bash
   pip install -r requirements.txt
   # or, minimal:
   pip install pyyaml librosa soundfile pandas tqdm \
               openai-whisper torch flask spacy transformers
   python -m spacy download en_core_web_sm
   ```
3. **(Windows) Add FFmpeg to PATH** â€“ Whisper uses it to load audio.

---

## âš™ï¸ Configuration (`config/configs.yaml`)

```yaml
audio_cleaning:
  input_path: "data/raw_audio"
  output_dir: "data/clean_audio"
  sr: 16000
  silence_db: 25
  target_dbfs: -3.0

whisper_transcribe:
  root_dir: "data/clean_audio"
  output_file: "data/transcripts/dev.parquet"
  model: "small"
  device: "cpu"  # change to "cuda" if GPU

text_cleaning:
  input_file: "data/transcripts/dev.parquet"
  output_csv: "data/transcripts/clean.csv"
  text_col: "text"
  lowercase: true
  remove_non_alpha: false
  remove_fillers: true

ner_summarise:
  input_csv: "data/transcripts/clean.csv"
  output_csv: "data/nlp/ner_summary.csv"
  spacy_model: "en_core_web_sm"
  t5_model: "t5-base"
```

---

## ğŸš€ Quick Start

```bash
# 1. Clean audio
python src/audio_cleaning.py

# 2. Batch ASR
python src/whisper_transcribe.py

# 3. Clean transcripts
python src/text_cleaning.py

# 4. NER & summarisation (optional)
python src/ner_summarise.py

# 5. Launch web UI
python src/app.py  # http://localhost:5000
```

---

## ğŸ“ NLP Stage Details

### spaCy NER (`ner_summarise.py`)

```python
import spacy, pandas as pd
nlp = spacy.load("en_core_web_sm")
...
```

Extracts entities and appends a JSON list to each row (`entities` column).

### T5 Summarisation

```python
from transformers import T5ForConditionalGeneration, T5Tokenizer
...
```

Generates three summary lengths via beamâ€‘search.

---

## ğŸ“‘ Flask UI Endpoints

| Route | Method | Description                               |
| ----- | ------ | ----------------------------------------- |
| `/`   | GET    | Upload form                               |
| `/`   | POST   | Process uploaded file and display results |

The UI calls **inâ€‘memory versions** of the pipeline (audio cleaning â†’ Whisper â†’ text cleaning â†’ NER â†’ summaries) and shows the final cleaned transcript plus extracted entities/summaries.

---

## ğŸ› ï¸ Troubleshooting

* **FileNotFoundError: ffmpeg** â€“ install FFmpeg and ensure itâ€™s on `PATH`.
* **CUDA out of memory** â€“ switch Whisper/T5 to `device: cpu` or use a smaller model (`tiny`, `base`).
* **spaCy model not found** â€“ run `python -m spacy download en_core_web_sm`.

---

## ğŸ“œ License & Acknowledgements

This project is MITâ€‘licensed. Built with OpenAIÂ Whisper, HuggingÂ Face Transformers, and spaCy â€“ thanks to those communities for the excellent openâ€‘source tooling.
